{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/clovaai/rebias/blob/master/datasets/colour_mnist.py\n",
    "\n",
    "class BiasedMNIST(MNIST):\n",
    "    \"\"\"A base class for Biased-MNIST.\n",
    "    We manually select ten colours to synthetic colour bias. (See `COLOUR_MAP` for the colour configuration)\n",
    "    Usage is exactly same as torchvision MNIST dataset class.\n",
    "    You have two paramters to control the level of bias.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str\n",
    "        path to MNIST dataset.\n",
    "    data_label_correlation : float, default=1.0\n",
    "        Here, each class has the pre-defined colour (bias).\n",
    "        data_label_correlation, or `rho` controls the level of the dataset bias.\n",
    "        A sample is coloured with\n",
    "            - the pre-defined colour with probability `rho`,\n",
    "            - coloured with one of the other colours with probability `1 - rho`.\n",
    "              The number of ``other colours'' is controlled by `n_confusing_labels` (default: 9).\n",
    "        Note that the colour is injected into the background of the image (see `_binary_to_colour`).\n",
    "        Hence, we have\n",
    "            - Perfectly biased dataset with rho=1.0\n",
    "            - Perfectly unbiased with rho=0.1 (1/10) ==> our ``unbiased'' setting in the test time.\n",
    "        In the paper, we explore the high correlations but with small hints, e.g., rho=0.999.\n",
    "    n_confusing_labels : int, default=9\n",
    "        In the real-world cases, biases are not equally distributed, but highly unbalanced.\n",
    "        We mimic the unbalanced biases by changing the number of confusing colours for each class.\n",
    "        In the paper, we use n_confusing_labels=9, i.e., during training, the model can observe\n",
    "        all colours for each class. However, you can make the problem harder by setting smaller n_confusing_labels, e.g., 2.\n",
    "        We suggest to researchers considering this benchmark for future researches.\n",
    "    \"\"\"\n",
    "\n",
    "    COLOUR_MAP = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [225, 225, 0], [225, 0, 225],\n",
    "                  [0, 255, 255], [255, 128, 0], [255, 0, 128], [128, 0, 255], [128, 128, 128]]\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, data_label_correlation=1.0, n_confusing_labels=9, do_shuffle=True):\n",
    "        super().__init__(root, train=train, transform=transform,\n",
    "                         target_transform=target_transform,\n",
    "                         download=download)\n",
    "        self.data_label_correlation = data_label_correlation\n",
    "        self.n_confusing_labels = n_confusing_labels\n",
    "        self.do_shuffle = do_shuffle\n",
    "        self.data, self.targets, self.biased_targets = self.build_biased_mnist()\n",
    "\n",
    "        \n",
    "        indices = np.arange(len(self.data))\n",
    "        \n",
    "        self._shuffle(indices)\n",
    "        self.data = self.data[indices].numpy()\n",
    "        self.targets = self.targets[indices]\n",
    "        self.biased_targets = self.biased_targets[indices]\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, 'processed')\n",
    "\n",
    "    def _shuffle(self, iteratable):\n",
    "        if self.do_shuffle:\n",
    "            np.random.shuffle(iteratable)\n",
    "\n",
    "    def _make_biased_mnist(self, indices, label):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _update_bias_indices(self, bias_indices, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            bias_indices: \n",
    "        \n",
    "        \"\"\"\n",
    "        if self.n_confusing_labels > 9 or self.n_confusing_labels < 1:\n",
    "            raise ValueError(self.n_confusing_labels)\n",
    "\n",
    "        indices = np.where((self.targets == label).numpy())[0]\n",
    "        self._shuffle(indices)\n",
    "        indices = torch.LongTensor(indices)\n",
    "\n",
    "        n_samples = len(indices)\n",
    "        n_correlated_samples = int(n_samples * self.data_label_correlation)\n",
    "        n_decorrelated_per_class = int(np.ceil((n_samples - n_correlated_samples) / (self.n_confusing_labels)))\n",
    "\n",
    "        correlated_indices = indices[:n_correlated_samples]\n",
    "        bias_indices[label] = torch.cat([bias_indices[label], correlated_indices])\n",
    "\n",
    "        decorrelated_indices = torch.split(indices[n_correlated_samples:], n_decorrelated_per_class)\n",
    "\n",
    "        other_labels = [_label % 10 for _label in range(label + 1, label + 1 + self.n_confusing_labels)]\n",
    "        self._shuffle(other_labels)\n",
    "\n",
    "        for idx, _indices in enumerate(decorrelated_indices):\n",
    "            _label = other_labels[idx]\n",
    "            bias_indices[_label] = torch.cat([bias_indices[_label], _indices])\n",
    "\n",
    "    def build_biased_mnist(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            data: batch of images of shape (N, 28, 28, 3)\n",
    "            targets: labels of shape (N) corresponding to data\n",
    "            biased_targets: index of background color to be used, shaped (N)\n",
    "        \"\"\"\n",
    "        n_labels = self.targets.max().item() + 1\n",
    "        bias_indices = {label: torch.LongTensor() for label in range(n_labels)}\n",
    "        \n",
    "        for label in range(n_labels):\n",
    "            self._update_bias_indices(bias_indices, label)\n",
    "\n",
    "        data = torch.ByteTensor()\n",
    "        targets = torch.LongTensor()\n",
    "        biased_targets = []\n",
    "\n",
    "        for bias_label, indices in bias_indices.items():\n",
    "            _data, _targets = self._make_biased_mnist(indices, bias_label)\n",
    "            data = torch.cat([data, _data])\n",
    "            targets = torch.cat([targets, _targets])\n",
    "            biased_targets.extend([bias_label] * len(indices))\n",
    "\n",
    "        biased_targets = torch.LongTensor(biased_targets)\n",
    "        return data, targets, biased_targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = Image.fromarray(img, mode='RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, int(self.biased_targets[index])\n",
    "    \n",
    "    \n",
    "    \n",
    "class ColourBiasedMNIST(BiasedMNIST):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, data_label_correlation=1.0, n_confusing_labels=9, do_shuffle=True):\n",
    "        super(ColourBiasedMNIST, self).__init__(root, train=train, transform=transform,\n",
    "                                                target_transform=target_transform,\n",
    "                                                download=download,\n",
    "                                                data_label_correlation=data_label_correlation,\n",
    "                                                n_confusing_labels=n_confusing_labels,\n",
    "                                                do_shuffle=do_shuffle)\n",
    "\n",
    "    def _binary_to_colour(self, data, colour):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: grey-scale image of shape (N, 28, 28)   \n",
    "        Returns:\n",
    "            RGB image of shape (N, 28, 28, 3)\n",
    "        \"\"\"\n",
    "        \n",
    "        fg_data = torch.zeros_like(data)\n",
    "        fg_data[data != 0] = 255\n",
    "        fg_data[data == 0] = 0\n",
    "        fg_data = torch.stack([fg_data, fg_data, fg_data], dim=1)\n",
    "\n",
    "        bg_data = torch.zeros_like(data)\n",
    "        bg_data[data == 0] = 1\n",
    "        bg_data[data != 0] = 0\n",
    "        bg_data = torch.stack([bg_data, bg_data, bg_data], dim=3)\n",
    "        bg_data = bg_data * torch.ByteTensor(colour)\n",
    "        bg_data = bg_data.permute(0, 3, 1, 2)\n",
    "\n",
    "        data = fg_data + bg_data\n",
    "        data = data.permute(0, 2, 3, 1)\n",
    "        return data\n",
    "\n",
    "    def _make_biased_mnist(self, indices, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            indices: indices to be turned into biased images, shaped (N)\n",
    "            label: a scalar index specifying a target colour to be used\n",
    "        Returns:\n",
    "            a tuple (images, labels)\n",
    "        \"\"\"\n",
    "        return self._binary_to_colour(self.data[indices], self.COLOUR_MAP[label]), self.targets[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "\n",
    "root=os.path.join('data', 'new')\n",
    "train=True\n",
    "data_label_correlation = 1\n",
    "n_confusing_labels = 9\n",
    "batch_size = 50\n",
    "num_workers = 1\n",
    "do_shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                         std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "mnist = MNIST(root, \n",
    "            train=train, \n",
    "            transform=transform,\n",
    "            download=True)\n",
    "\n",
    "dataset = ColourBiasedMNIST(root, \n",
    "                            train=train, \n",
    "                            transform=transform,\n",
    "                            download=True, \n",
    "                            data_label_correlation=data_label_correlation, \n",
    "                            n_confusing_labels=n_confusing_labels,\n",
    "                            do_shuffle=do_shuffle)\n",
    "\n",
    "dataloader = data.DataLoader(dataset=dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             num_workers=num_workers,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.data.shape) \n",
    "print(dataset.train_data.shape) \n",
    "print(dataset.test_data.shape)\n",
    "print(dataset.targets.shape)\n",
    "\n",
    "print(mnist.data.shape)\n",
    "print(mnist.train_data.shape)\n",
    "print(mnist.test_data.shape)\n",
    "print(mnist.targets.shape)\n",
    "\n",
    "# dataset.test_data == dataset.train_data == dataset.data\n",
    "print(torch.sum(mnist.test_data == mnist.train_data).item() / 60000)\n",
    "print(torch.sum(torch.tensor(dataset.test_data == dataset.train_data)).item() / 60000 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data = dataset.data[0:50000]\n",
    "dataset.targets = dataset.targets[0:50000]\n",
    "dl = data.DataLoader(dataset, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dl.dataset.data.shape)\n",
    "print(dl.dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "img = dl.dataset.data[1]\n",
    "img = np.swapaxes(img, 0, 1)\n",
    "img = np.swapaxes(img, 1, 2)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "# img_batch = np.array([dataset[0][0].data.numpy(), dataset[1][0].data.numpy()])\n",
    "# img_batch.shape\n",
    "img = dataset[11][0].data.numpy()\n",
    "img = np.swapaxes(img, 0, 1)\n",
    "img = np.swapaxes(img, 1, 2)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOUR_MAP = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [225, 225, 0], [225, 0, 225],\n",
    "                  [0, 255, 255], [255, 128, 0], [255, 0, 128], [128, 0, 255], [128, 128, 128]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing randomly-colored backgruond\n",
    "\n",
    "# ind = np.array([0, 1])\n",
    "ind = np.random.randint(10, size=2)\n",
    "colors = np.array(COLOUR_MAP)[ind]\n",
    "print(colors)\n",
    "\n",
    "a = torch.ByteTensor(colors)\n",
    "# a = torch.ByteTensor([255, 0, 0])\n",
    "a = a.unsqueeze(1)\n",
    "a = a.unsqueeze(2)\n",
    "print(a)\n",
    "b = torch.tensor(np.random.randn(2, 4, 4, 3))\n",
    "print(b)\n",
    "print(b * a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing seeded rng\n",
    "\n",
    "rng = np.random.default_rng(seed=1)\n",
    "a = np.array(range(10))\n",
    "rng.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0, 0, 0],\n",
      "           [0, 1, 1],\n",
      "           [0, 1, 1],\n",
      "           [1, 1, 1]],\n",
      "\n",
      "          [[1, 1, 1],\n",
      "           [1, 0, 1],\n",
      "           [1, 0, 1],\n",
      "           [1, 0, 1]],\n",
      "\n",
      "          [[0, 1, 0],\n",
      "           [0, 1, 0],\n",
      "           [0, 0, 1],\n",
      "           [0, 0, 0]],\n",
      "\n",
      "          [[1, 1, 0],\n",
      "           [1, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 0]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1, 0, 1],\n",
      "           [1, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [0, 1, 0]],\n",
      "\n",
      "          [[0, 1, 0],\n",
      "           [1, 1, 0],\n",
      "           [1, 1, 0],\n",
      "           [1, 1, 1]],\n",
      "\n",
      "          [[0, 1, 0],\n",
      "           [0, 1, 0],\n",
      "           [0, 0, 0],\n",
      "           [0, 1, 0]],\n",
      "\n",
      "          [[0, 0, 1],\n",
      "           [0, 1, 0],\n",
      "           [0, 0, 0],\n",
      "           [0, 1, 0]]]]], dtype=torch.int32)\n",
      "tensor([[[[[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [255,   0,   0]],\n",
      "\n",
      "          [[255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [255,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [255,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0, 255,   0]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0, 255]],\n",
      "\n",
      "          [[  0,   0, 255],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0, 255]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0, 225,   0],\n",
      "           [  0, 225,   0],\n",
      "           [225, 225,   0]],\n",
      "\n",
      "          [[225, 225,   0],\n",
      "           [225,   0,   0],\n",
      "           [225,   0,   0],\n",
      "           [225,   0,   0]],\n",
      "\n",
      "          [[  0, 225,   0],\n",
      "           [  0, 225,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[225, 225,   0],\n",
      "           [225,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [225,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0,   0, 225],\n",
      "           [  0,   0, 225],\n",
      "           [225,   0, 225]],\n",
      "\n",
      "          [[225,   0, 225],\n",
      "           [225,   0, 225],\n",
      "           [225,   0, 225],\n",
      "           [225,   0, 225]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 225],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[225,   0,   0],\n",
      "           [225,   0,   0],\n",
      "           [  0,   0, 225],\n",
      "           [225,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0, 255, 255],\n",
      "           [  0, 255, 255],\n",
      "           [  0, 255, 255]],\n",
      "\n",
      "          [[  0, 255, 255],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0, 255]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0, 128,   0],\n",
      "           [  0, 128,   0],\n",
      "           [255, 128,   0]],\n",
      "\n",
      "          [[255, 128,   0],\n",
      "           [255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [255,   0,   0]],\n",
      "\n",
      "          [[  0, 128,   0],\n",
      "           [  0, 128,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[255, 128,   0],\n",
      "           [255,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [255,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0,   0, 128],\n",
      "           [  0,   0, 128],\n",
      "           [255,   0, 128]],\n",
      "\n",
      "          [[255,   0, 128],\n",
      "           [255,   0, 128],\n",
      "           [255,   0, 128],\n",
      "           [255,   0, 128]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 128],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [  0,   0, 128],\n",
      "           [255,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0, 255],\n",
      "           [128,   0, 255]],\n",
      "\n",
      "          [[128,   0, 255],\n",
      "           [128,   0, 255],\n",
      "           [128,   0, 255],\n",
      "           [128,   0, 255]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[128,   0,   0],\n",
      "           [128,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [128,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0, 128, 128],\n",
      "           [  0, 128, 128],\n",
      "           [128, 128, 128]],\n",
      "\n",
      "          [[128, 128, 128],\n",
      "           [128,   0, 128],\n",
      "           [128,   0, 128],\n",
      "           [128,   0, 128]],\n",
      "\n",
      "          [[  0, 128,   0],\n",
      "           [  0, 128,   0],\n",
      "           [  0,   0, 128],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[128, 128,   0],\n",
      "           [128,   0,   0],\n",
      "           [  0,   0, 128],\n",
      "           [128,   0,   0]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [255,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 255,   0]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0, 255,   0]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 255,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 255,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0, 255],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 255]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0, 255],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[225,   0,   0],\n",
      "           [225,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 225,   0]],\n",
      "\n",
      "          [[  0, 225,   0],\n",
      "           [225, 225,   0],\n",
      "           [225, 225,   0],\n",
      "           [225, 225,   0]],\n",
      "\n",
      "          [[  0, 225,   0],\n",
      "           [  0, 225,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 225,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0, 225,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 225,   0]]],\n",
      "\n",
      "\n",
      "         [[[225,   0, 225],\n",
      "           [225,   0,   0],\n",
      "           [  0,   0, 225],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [225,   0,   0],\n",
      "           [225,   0,   0],\n",
      "           [225,   0, 225]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0, 225],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[  0,   0, 255],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0, 255,   0]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0, 255, 255]],\n",
      "\n",
      "          [[  0, 255,   0],\n",
      "           [  0, 255,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 255,   0]],\n",
      "\n",
      "          [[  0,   0, 255],\n",
      "           [  0, 255,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 255,   0]]],\n",
      "\n",
      "\n",
      "         [[[255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 128,   0]],\n",
      "\n",
      "          [[  0, 128,   0],\n",
      "           [255, 128,   0],\n",
      "           [255, 128,   0],\n",
      "           [255, 128,   0]],\n",
      "\n",
      "          [[  0, 128,   0],\n",
      "           [  0, 128,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 128,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0, 128,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 128,   0]]],\n",
      "\n",
      "\n",
      "         [[[255,   0, 128],\n",
      "           [255,   0,   0],\n",
      "           [  0,   0, 128],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [255,   0,   0],\n",
      "           [255,   0, 128]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0, 128],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[128,   0, 255],\n",
      "           [128,   0,   0],\n",
      "           [  0,   0, 255],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [128,   0,   0],\n",
      "           [128,   0,   0],\n",
      "           [128,   0, 255]],\n",
      "\n",
      "          [[  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]],\n",
      "\n",
      "          [[  0,   0, 255],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "         [[[128,   0, 128],\n",
      "           [128,   0,   0],\n",
      "           [  0,   0, 128],\n",
      "           [  0, 128,   0]],\n",
      "\n",
      "          [[  0, 128,   0],\n",
      "           [128, 128,   0],\n",
      "           [128, 128,   0],\n",
      "           [128, 128, 128]],\n",
      "\n",
      "          [[  0, 128,   0],\n",
      "           [  0, 128,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 128,   0]],\n",
      "\n",
      "          [[  0,   0, 128],\n",
      "           [  0, 128,   0],\n",
      "           [  0,   0,   0],\n",
      "           [  0, 128,   0]]]]])\n",
      "torch.Size([2, 10, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Testing augmentation\n",
    "# Need (N, 1, 4, 4, 3) -> (N, 10, 4, 4, 3)\n",
    "# m:(10, 3) -> (10, 1, 1, 3)\n",
    "\n",
    "a = torch.tensor(np.random.randint(2, size=(2, 4, 4, 3))).unsqueeze(1)\n",
    "m = torch.tensor(COLOUR_MAP).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "b = m * a\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
