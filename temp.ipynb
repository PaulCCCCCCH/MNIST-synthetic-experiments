{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/clovaai/rebias/blob/master/datasets/colour_mnist.py\n",
    "\n",
    "class BiasedMNIST(MNIST):\n",
    "    \"\"\"A base class for Biased-MNIST.\n",
    "    We manually select ten colours to synthetic colour bias. (See `COLOUR_MAP` for the colour configuration)\n",
    "    Usage is exactly same as torchvision MNIST dataset class.\n",
    "    You have two paramters to control the level of bias.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str\n",
    "        path to MNIST dataset.\n",
    "    data_label_correlation : float, default=1.0\n",
    "        Here, each class has the pre-defined colour (bias).\n",
    "        data_label_correlation, or `rho` controls the level of the dataset bias.\n",
    "        A sample is coloured with\n",
    "            - the pre-defined colour with probability `rho`,\n",
    "            - coloured with one of the other colours with probability `1 - rho`.\n",
    "              The number of ``other colours'' is controlled by `n_confusing_labels` (default: 9).\n",
    "        Note that the colour is injected into the background of the image (see `_binary_to_colour`).\n",
    "        Hence, we have\n",
    "            - Perfectly biased dataset with rho=1.0\n",
    "            - Perfectly unbiased with rho=0.1 (1/10) ==> our ``unbiased'' setting in the test time.\n",
    "        In the paper, we explore the high correlations but with small hints, e.g., rho=0.999.\n",
    "    n_confusing_labels : int, default=9\n",
    "        In the real-world cases, biases are not equally distributed, but highly unbalanced.\n",
    "        We mimic the unbalanced biases by changing the number of confusing colours for each class.\n",
    "        In the paper, we use n_confusing_labels=9, i.e., during training, the model can observe\n",
    "        all colours for each class. However, you can make the problem harder by setting smaller n_confusing_labels, e.g., 2.\n",
    "        We suggest to researchers considering this benchmark for future researches.\n",
    "    \"\"\"\n",
    "\n",
    "    COLOUR_MAP = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [225, 225, 0], [225, 0, 225],\n",
    "                  [0, 255, 255], [255, 128, 0], [255, 0, 128], [128, 0, 255], [128, 128, 128]]\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, data_label_correlation=1.0, n_confusing_labels=9, do_shuffle=True):\n",
    "        super().__init__(root, train=train, transform=transform,\n",
    "                         target_transform=target_transform,\n",
    "                         download=download)\n",
    "        self.data_label_correlation = data_label_correlation\n",
    "        self.n_confusing_labels = n_confusing_labels\n",
    "        self.do_shuffle = do_shuffle\n",
    "        self.data, self.targets, self.biased_targets = self.build_biased_mnist()\n",
    "\n",
    "        \n",
    "        indices = np.arange(len(self.data))\n",
    "        \n",
    "        self._shuffle(indices)\n",
    "        self.data = self.data[indices].numpy()\n",
    "        self.targets = self.targets[indices]\n",
    "        self.biased_targets = self.biased_targets[indices]\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, 'processed')\n",
    "\n",
    "    def _shuffle(self, iteratable):\n",
    "        if self.do_shuffle:\n",
    "            np.random.shuffle(iteratable)\n",
    "\n",
    "    def _make_biased_mnist(self, indices, label):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _update_bias_indices(self, bias_indices, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            bias_indices: \n",
    "        \n",
    "        \"\"\"\n",
    "        if self.n_confusing_labels > 9 or self.n_confusing_labels < 1:\n",
    "            raise ValueError(self.n_confusing_labels)\n",
    "\n",
    "        indices = np.where((self.targets == label).numpy())[0]\n",
    "        self._shuffle(indices)\n",
    "        indices = torch.LongTensor(indices)\n",
    "\n",
    "        n_samples = len(indices)\n",
    "        n_correlated_samples = int(n_samples * self.data_label_correlation)\n",
    "        n_decorrelated_per_class = int(np.ceil((n_samples - n_correlated_samples) / (self.n_confusing_labels)))\n",
    "\n",
    "        correlated_indices = indices[:n_correlated_samples]\n",
    "        bias_indices[label] = torch.cat([bias_indices[label], correlated_indices])\n",
    "\n",
    "        decorrelated_indices = torch.split(indices[n_correlated_samples:], n_decorrelated_per_class)\n",
    "\n",
    "        other_labels = [_label % 10 for _label in range(label + 1, label + 1 + self.n_confusing_labels)]\n",
    "        self._shuffle(other_labels)\n",
    "\n",
    "        for idx, _indices in enumerate(decorrelated_indices):\n",
    "            _label = other_labels[idx]\n",
    "            bias_indices[_label] = torch.cat([bias_indices[_label], _indices])\n",
    "\n",
    "    def build_biased_mnist(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            data: batch of images of shape (N, 28, 28, 3)\n",
    "            targets: labels of shape (N) corresponding to data\n",
    "            biased_targets: index of background color to be used, shaped (N)\n",
    "        \"\"\"\n",
    "        n_labels = self.targets.max().item() + 1\n",
    "        bias_indices = {label: torch.LongTensor() for label in range(n_labels)}\n",
    "        \n",
    "        for label in range(n_labels):\n",
    "            self._update_bias_indices(bias_indices, label)\n",
    "\n",
    "        data = torch.ByteTensor()\n",
    "        targets = torch.LongTensor()\n",
    "        biased_targets = []\n",
    "\n",
    "        for bias_label, indices in bias_indices.items():\n",
    "            _data, _targets = self._make_biased_mnist(indices, bias_label)\n",
    "            data = torch.cat([data, _data])\n",
    "            targets = torch.cat([targets, _targets])\n",
    "            biased_targets.extend([bias_label] * len(indices))\n",
    "\n",
    "        biased_targets = torch.LongTensor(biased_targets)\n",
    "        return data, targets, biased_targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = Image.fromarray(img, mode='RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, int(self.biased_targets[index])\n",
    "    \n",
    "    \n",
    "    \n",
    "class ColourBiasedMNIST(BiasedMNIST):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, data_label_correlation=1.0, n_confusing_labels=9, do_shuffle=True):\n",
    "        super(ColourBiasedMNIST, self).__init__(root, train=train, transform=transform,\n",
    "                                                target_transform=target_transform,\n",
    "                                                download=download,\n",
    "                                                data_label_correlation=data_label_correlation,\n",
    "                                                n_confusing_labels=n_confusing_labels,\n",
    "                                                do_shuffle=do_shuffle)\n",
    "\n",
    "    def _binary_to_colour(self, data, colour):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: grey-scale image of shape (N, 28, 28)   \n",
    "        Returns:\n",
    "            RGB image of shape (N, 28, 28, 3)\n",
    "        \"\"\"\n",
    "        \n",
    "        fg_data = torch.zeros_like(data)\n",
    "        fg_data[data != 0] = 255\n",
    "        fg_data[data == 0] = 0\n",
    "        fg_data = torch.stack([fg_data, fg_data, fg_data], dim=1)\n",
    "\n",
    "        bg_data = torch.zeros_like(data)\n",
    "        bg_data[data == 0] = 1\n",
    "        bg_data[data != 0] = 0\n",
    "        bg_data = torch.stack([bg_data, bg_data, bg_data], dim=3)\n",
    "        bg_data = bg_data * torch.ByteTensor(colour)\n",
    "        bg_data = bg_data.permute(0, 3, 1, 2)\n",
    "\n",
    "        data = fg_data + bg_data\n",
    "        data = data.permute(0, 2, 3, 1)\n",
    "        return data\n",
    "\n",
    "    def _make_biased_mnist(self, indices, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            indices: indices to be turned into biased images, shaped (N)\n",
    "            label: a scalar index specifying a target colour to be used\n",
    "        Returns:\n",
    "            a tuple (images, labels)\n",
    "        \"\"\"\n",
    "        return self._binary_to_colour(self.data[indices], self.COLOUR_MAP[label]), self.targets[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "\n",
    "root=os.path.join('data', 'new')\n",
    "train=True\n",
    "data_label_correlation = 1\n",
    "n_confusing_labels = 9\n",
    "batch_size = 50\n",
    "num_workers = 1\n",
    "do_shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                         std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "mnist = MNIST(root, \n",
    "            train=train, \n",
    "            transform=transform,\n",
    "            download=True)\n",
    "\n",
    "dataset = ColourBiasedMNIST(root, \n",
    "                            train=train, \n",
    "                            transform=transform,\n",
    "                            download=True, \n",
    "                            data_label_correlation=data_label_correlation,\n",
    "                            n_confusing_labels=n_confusing_labels,\n",
    "                            do_shuffle=do_shuffle)\n",
    "\n",
    "dataloader = data.DataLoader(dataset=dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             num_workers=num_workers,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 3)\n",
      "(60000, 28, 28, 3)\n",
      "(60000, 28, 28, 3)\n",
      "torch.Size([60000])\n",
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "784.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\torch-env\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "E:\\anaconda\\envs\\torch-env\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784.0\n"
     ]
    }
   ],
   "source": [
    "print(dataset.data.shape) \n",
    "print(dataset.train_data.shape) \n",
    "print(dataset.test_data.shape)\n",
    "print(dataset.targets.shape)\n",
    "\n",
    "print(mnist.data.shape)\n",
    "print(mnist.train_data.shape)\n",
    "print(mnist.test_data.shape)\n",
    "print(mnist.targets.shape)\n",
    "\n",
    "# dataset.test_data == dataset.train_data == dataset.data\n",
    "print(torch.sum(mnist.test_data == mnist.train_data).item() / 60000)\n",
    "print(torch.sum(torch.tensor(dataset.test_data == dataset.train_data)).item() / 60000 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data = dataset.data[0:50000]\n",
    "dataset.targets = dataset.targets[0:50000]\n",
    "dl = data.DataLoader(dataset, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 3)\n",
      "torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "print(dl.dataset.data.shape)\n",
    "print(dl.dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "img = dl.dataset.data[1]\n",
    "img = np.swapaxes(img, 0, 1)\n",
    "img = np.swapaxes(img, 1, 2)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "# img_batch = np.array([dataset[0][0].data.numpy(), dataset[1][0].data.numpy()])\n",
    "# img_batch.shape\n",
    "img = dataset[1][0].data.numpy()\n",
    "img = np.swapaxes(img, 0, 1)\n",
    "img = np.swapaxes(img, 1, 2)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
